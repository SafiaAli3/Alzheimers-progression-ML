{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+LmzTrpCrieWqRjRs+V7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SafiaAli3/Alzheimers-progression-ML/blob/main/Model_2_random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FWkXHSc5NTql"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Df.csv')\n",
        "df = df[df['Visit'] == 1].copy()\n",
        "\n",
        "X = df.drop(columns=['Label', 'Subject ID', 'MRI ID', 'Group', 'Visit', 'Hand'], errors='ignore')\n",
        "y = df['Label']"
      ],
      "metadata": {
        "id": "pSMYosCYNe-c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = ['Age', 'EDUC', 'SES', 'eTIV', 'nWBV', 'ASF']\n",
        "categorical_features = ['M/F']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_features),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
        "])\n"
      ],
      "metadata": {
        "id": "yw-C7LlUNhf5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n"
      ],
      "metadata": {
        "id": "M9yCtwT8NjZQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neUyHcRCNlIc",
        "outputId": "35bdb23b-1e86-4cf2-d997-20c861a21261"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.53      0.57        15\n",
            "           1       0.53      0.62      0.57        13\n",
            "\n",
            "    accuracy                           0.57        28\n",
            "   macro avg       0.57      0.57      0.57        28\n",
            "weighted avg       0.58      0.57      0.57        28\n",
            "\n",
            "[[8 7]\n",
            " [5 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(pipeline, X, y, cv=5, scoring='f1_macro')\n",
        "print(\"F1 Macro scores for each fold:\", scores)\n",
        "print(\"Average F1 Macro:\", scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMEQDqoROWYR",
        "outputId": "bcc8ce86-83d3-417f-932c-882eb1b11a1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Macro scores for each fold: [0.63541667 0.66666667 0.66482759 0.5        0.69318182]\n",
            "Average F1 Macro: 0.6320185475444097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [None, 5, 10],\n",
        "    'classifier__min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro')\n",
        "grid.fit(X, y)\n",
        "\n",
        "print(\"Best F1 Macro:\", grid.best_score_)\n",
        "print(\"Best Params:\", grid.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crlg-cZzOdpG",
        "outputId": "39d9fe9e-3bda-474f-8d17-0530b2dc079c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best F1 Macro: 0.6858151180283016\n",
            "Best Params: {'classifier__max_depth': 5, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 2 Summary**: Random Forest Classifier\n",
        "\n",
        "The second model uses a Random Forest Classifier to predict whether a subject is demented or nondemented based on clinical and MRI-based features from the OASIS dataset.\n",
        "\n",
        "**Preprocessing**\n",
        "\n",
        "Applied StandardScaler to numeric features: Age, EDUC, SES, eTIV, nWBV, ASF\n",
        "\n",
        "Used OneHotEncoder for the categorical gender column (M/F)\n",
        "\n",
        "Combined using ColumnTransformer and wrapped in a Pipeline\n",
        "\n",
        "**Performance**\n",
        "\n",
        "Initial 5-fold cross-validation:\n",
        "F1 Macro scores: [0.63, 0.67, 0.66, 0.50, 0.69]\n",
        "→ Average F1 Macro: 0.63\n",
        "\n",
        "After Hyperparameter Tuning (GridSearchCV):\n",
        "Best parameters: max_depth=5, min_samples_split=5, n_estimators=100\n",
        "→ Best F1 Macro: 0.686\n",
        "\n",
        "**Confusion Matrix Insights** **bold text**\n",
        "\n",
        "The model achieved balanced performance across both classes\n",
        "\n",
        "Correctly identified most demented patients, but still made a few false predictions in both directions\n",
        "\n",
        "Shows stronger performance than logistic regression, with better generalization after tuning\n",
        "\n",
        "This model serves as a strong baseline for structured medical data, demonstrating the value of tree-based ensembles in early dementia detection tasks."
      ],
      "metadata": {
        "id": "F__JN2R4PuVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion – Model 2: Random Forest Classifier**\n",
        "\n",
        "\n",
        "The Random Forest Classifier proved to be a more effective model than logistic regression for predicting dementia status based on demographic and MRI-derived features. After applying appropriate preprocessing and hyperparameter tuning, the model achieved a macro F1 score of 0.686, showing improved performance and better generalization.\n",
        "\n",
        "The model was able to balance precision and recall across both classes, making it a reliable baseline for structured clinical data. While the dataset was relatively small, the results suggest that tree-based ensemble methods can capture non-linear relationships and interactions among features that linear models may miss.\n",
        "\n",
        "Overall, this model demonstrates the potential of machine learning in supporting early Alzheimer’s detection and provides a solid foundation for future work involving larger datasets, longitudinal modeling, or neural networks."
      ],
      "metadata": {
        "id": "Rb7-NSGkQ1f1"
      }
    }
  ]
}