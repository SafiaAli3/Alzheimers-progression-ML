{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTGq/+6Lne+MkmL0tirBo7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SafiaAli3/Alzheimers-progression-ML/blob/main/Model_1_logistic_regression_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression** is a widely used statistical model for binary classification problems, where the goal is to predict one of two possible outcomes — in this case, whether a subject is demented (1) or nondemented (0) based on clinical and MRI-derived features."
      ],
      "metadata": {
        "id": "ckr-Ss7Q_jAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing and Pipeline**\n",
        "\n",
        "\n",
        "I used a ColumnTransformer to separately handle numeric and categorical data:\n",
        "\n",
        "*Numeric features* (like age, eTIV, nWBV) were scaled with StandardScaler() to standardize units.\n",
        "\n",
        "*Categorical feature* (M/F) was one-hot encoded to make it machine-readable.\n",
        "\n",
        "This was wrapped in a Pipeline to combine preprocessing and model training into one step. It helps prevent data leakage, keeps the code clean, and makes it easy to swap models later."
      ],
      "metadata": {
        "id": "gQOdEbmXB53_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rM546IPZ-wrZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar_df = pd.read_csv('/content/Df.csv')\n",
        "df = scalar_df[scalar_df['Visit'] == 1].copy()\n",
        "\n",
        "X = df.drop(columns=['Label', 'Subject ID', 'MRI ID', 'Group', 'Visit', 'Hand'], errors='ignore')\n",
        "y = df['Label']\n",
        "\n",
        "print(X.shape, y.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etPDEmpq_ACQ",
        "outputId": "25d9c64d-9156-4dbb-d916-f15fae839aab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(136, 10) Label\n",
            "0    72\n",
            "1    64\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = ['Age', 'EDUC', 'SES', 'eTIV', 'nWBV', 'ASF']\n",
        "categorical_features = ['M/F']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_features),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', random_state=42))\n",
        "])\n"
      ],
      "metadata": {
        "id": "0fVmZcJwCPyV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "\n",
        "print(\"Logistic Regression Model Evaluation:\")\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po4tLPe1CTsF",
        "outputId": "3227a872-494a-45e1-9ace-d0c1c1b8cdaa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.60      0.62        15\n",
            "           1       0.57      0.62      0.59        13\n",
            "\n",
            "    accuracy                           0.61        28\n",
            "   macro avg       0.61      0.61      0.61        28\n",
            "weighted avg       0.61      0.61      0.61        28\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "extWGFPnCmDi",
        "outputId": "1520a308-f45e-4645-d05e-252ac30e87d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "[[9 6]\n",
            " [5 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix revealed that while the model correctly classified both demented and nondemented subjects, it made several false predictions. It misclassified 6 nondemented as demented and 5 demented as nondemented, indicating room for improvement. This reinforces the need for a more complex or better-tuned model, especially given the medical importance of correctly identifying demented individuals."
      ],
      "metadata": {
        "id": "xfY5mQ5JG_8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLq5kiKLDVpc",
        "outputId": "cbbf5cfd-1623-4aed-d74b-f625ba144932"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6071428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:**\n",
        "\n",
        "| Metric              | Meaning                                                                                             |\n",
        "| -------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| Accuracy = 61%       | Model correctly classified 17 out of 28 patients                                                                                               |\n",
        "| Class 0 F1 = 0.62    | Nondemented patients are predicted fairly well                                                                                                 |\n",
        "| Class 1 F1 = 0.59    | Demented patients are slightly harder to detect, but still reasonable                                                                          |\n",
        "| Balanced metrics     | The model isn’t heavily biased toward one class (which is good)                                                                                |\n",
        "| Room for improvement | 61% accuracy means the model is learning, but better performance may come from more data or a more complex model like Random Forest or XGBoost |\n"
      ],
      "metadata": {
        "id": "6hPLyssyFXaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "The logistic regression model serves as a simple, interpretable baseline for dementia classification using demographic and MRI-based features. It achieved 61% accuracy and relatively balanced precision and recall between classes. While performance is modest, it provides a meaningful starting point for more advanced models like Random Forest or neural networks."
      ],
      "metadata": {
        "id": "uDwRzOpjGT-a"
      }
    }
  ]
}